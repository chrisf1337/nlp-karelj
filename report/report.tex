%
% File acl2016.tex
%
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn,
%% based on the style files for ACL-2010, which were, in turn,
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2016}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym,graphicx,listings,hyperref,booktabs,array,microtype}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}
\lstset{basicstyle=\ttfamily\footnotesize,breaklines=true}

\title{A Dependency-Parser-Based Approach to Converting Natural Language English Sentences to Karel J\ Robot Code}

\author{
    % First Author \\
    % Affiliation / Address line 1 \\
    % Affiliation / Address line 2 \\
    % Affiliation / Address line 3 \\
    % {\tt email@domain} \\\And
    % Second Author \\
    % Affiliation / Address line 1 \\
    % Affiliation / Address line 2 \\
    % Affiliation / Address line 3 \\
    % {\tt email@domain} \\}
    Christopher Fu \\
    \texttt{christopher.fu@yale.edu} \\}
\date{}

\begin{document}
\maketitle
\begin{abstract}
Students first starting to learn programming can often articulate how to solve problems in natural
language but have difficulty converting their thoughts into actual code. Metafor, an existing
project by Liu and Lieberman, allows users to describe a narrative and to receive a visualization
of their narrative in the form of ``scaffolding code,'' which can help them convert their ideas to
code. In the same vein, we aim to construct a parser and code generator that converts English
language sentences into Karel J Robot Java source code.
\end{abstract}

\section{Introduction}
Programming students often find that when they are first learning how to to program, accurately
translating what they want their program to do into actual code is harder than expected. Newell and
Card~\shortcite{Newell:1985aa} suggest that one factor contributing to this difficulty is that most
popular programming languages are not particularly designed with human-computer interaction issues
in mind. Some programming languages more easily lend themselves to a natural translation between
programmer intent and actual code, a concept that Green and Petre~\shortcite{Green:1996aa} term
\emph{closeness of mapping}.

Consider the following example based on one that Green and Petre give: we wish to sum up a sequence
of $N$ integers. In C, we could write a program like the one shown in Figure~\ref{fig:c-prog}.
Though writing such a program is second-nature for an experienced programmer, there is a large
amount of implicit knowledge contained in such a program that must be remembered by a novice
programmer. For example, we must recall the syntax of a variable declaration and a \texttt{for}
loop, and we must remember which lines must be terminated with a semicolon which lines do not. We
must also recall that arrays are 0-indexed, and the indexing variable \texttt{i} must run from 0 to
$N - 1$. Even experienced programmers may inadvertently commit a so-called ``off-by-one error''
from time to time. On the other hand, in Python, we could write a program shown in Figure
~\ref{fig:python-prog}. The Python program does away with much of the C program's syntactical
clutter---there are no curly braces to delimit a block and no \texttt{for} loop to begin with---
and the (intuitively-named) function \texttt{sum()} performs the summing action.  The Python
program more closely maps the programmer's intent to the actual code required to realize his
intent.

\begin{figure}[ht]
\begin{lstlisting}[language=C]
int s = 0;
for (int i = 0; i < N; i++) {
    s += arr[i];
}
\end{lstlisting}
\label{fig:c-prog}
\caption{C program calculating the sum of $N$ integers in \texttt{arr}.}
\end{figure}

\begin{figure}[ht]
\begin{lstlisting}[language=python]
s = sum(arr)
\end{lstlisting}
\label{fig:python-prog}
\caption{Python program calculating the sum of $N$ integers in \texttt{arr}.}
\end{figure}

In addition to using a more natural programming language, students also often work with a
restricted subset of a programming language to prevent all of the complexities of the language from
overwhelming them. Karel J Robot is a popular library that is used to teach students objected-
oriented Java programming in high school and university introductory-level programming
courses~\cite{Bergin:2013aa}. In the Karel universe, there are three types of entities---robots,
beepers, and walls. Robots can move around on a 2D grid and pick up or drop beepers at grid
coordinates. Walls impede the movement of robots, and robots that attempt to move through a wall
blocking their path perform an error shut off. Robots also have the ability to check if they occupy
the same grid coordinate, if they are in front of a wall, or if they are facing in one of the four
cardinal directions. Figure~\ref{fig:karel-ex} shows an example of a Karel world with a robot
facing south and two beepers. A description of the Karel J Robot API can be found at
\url{http://www.cs.gordon.edu/courses/cs112/KJRdocs/index.html}.

\begin{figure}[ht]
\centering
\includegraphics[width=\columnwidth]{karel-ex.png}
\caption{An example Karel world with a robot facing south and two beepers.}
\label{fig:karel-ex}
\end{figure}

We aim to construct a parser and code generator that converts English language sentences into Karel
J Robot Java source code. Such an application may be helpful to novice programmers who have an
approach to solving a problem that they can articulate naturally in English but do not know how
exactly to convert their approach into actual code.

\section{Related Work}
This project is heavily inspired by Metafor, an application written by Hugo Liu and Henry Lieberman
at the MIT Media Lab~\shortcite{Liu:2005aa} that presents an interface to the user to type a
story in English describing a scenario. As the user adds more details to his story, Metafor
develops a side-by-side ``visualization'' of the person's narrative in ``pseudo-Python''
\emph{scaffolding code}, which may not necessarily be directly executable but roughly describes the
user's intent behind the narrative. Metafor is integrated with a large knowledge base of common
sense knowledge, a programmatic interpreter that identifies special constructs and objects for
which there exists some common-sense-type information (e.g., colors and flavors), and a knowledge
representation of the code model that dynamically updates itself as new information from the user
is incorporated. Metafor is much more ambitious than our project in that its scope is much broader.
It aims to understand broad narratives using its common sense knowledge base. Our project is
comparatively much simpler because it aims to parse a limited subset of English sentences that make
sense in the constrained Karel universe problem space.

This project also draws inspiration from~\newcite{Pane:2001aa}, which explored how non-programmers
expressed solutions to a set of common representative programming tasks. Pane et al.\ found that
students most commonly described solutions in a declarative style using production-rule or event-
based statements beginning with \emph{if} or \emph{when}. In addition, students also used
imperative statements to describe local control flow, which suggests that students naturally use a
variety of programming styles to solve problems, and that designers of programming languages and
environments can increase the usability of their products by accommodating a mix of styles. We
tried to keep these ideas in mind when designing our parser implementation.

\section{Approach}
In the time available, we were only able to implement and test a simple approach, which consists of
two phases: a parsing phase to convert English language sentences into a list of action statements
that represent the actions a Karel robot should take to satisfy the intent conveyed by the
sentence, and a code generation phase to generate Java code from the output of the parsing phase.
In the parsing phase, we first perform a search of the sentence to be parsed for words we were
interested in. Such words include verbs that indicate a Karel robot action of some sort (e.g.,
``move'' and ``turn''), numbers and directions that modify actions in some way (e.g. ``two'' and
``north'' in the sentence ``Move two spaces north.''), and verbs that indicate a type of
conditional statement (e.g., ``facing'' in ``if Karel is facing north''). \texttt{while} and
\texttt{for} loops are not supported at this time. These words are then grouped together using
information from the Stanford CoreNLP dependency parser~\cite{Manning:2014aa}, and these groupings
are in turn converted into discrete action or conditional statements, which are one-to-one mappings
to lines of Karel Java code, based on what types of words are in each grouping. In the code
generation phase, we convert the actions and conditionals into Java code and inject the into a
template file that contains some boilerplate code that handles world initialization and
visualization. This final Java file output can be provided to the student to aid them in
visualizing how their English language Karel commands can be expressed in Karel Java code. The Java
source can also be compiled and run in a Karel simulator supplied in \texttt{KarelJRobot.jar}.

\begin{figure}[ht]
\centering
\includegraphics[width=\columnwidth]{parse-output.png}
\caption{Parser output for the sentence ``If Karel has a beeper and is facing north, move north two
steps and turn south.''}
\label{fig:parse-output}
\end{figure}

\begin{figure}[ht]
\begin{lstlisting}[language=java]
if (karel.anyBeepersInBeeperBag() && karel.facingNorth()) {
    while (!karel.facingNorth()) {
        karel.turnLeft();
    }
    karel.move(2);
    while (!karel.facingSouth()) {
        karel.turnLeft();
    }
}
\end{lstlisting}
\label{fig:injected-code}
\caption{The parser output in Figure~\ref{fig:parse-output} is converted into Java code in the code
generation phase, which is injected into a Java source file that can be compiled into a Java class
file.}
\end{figure}

\section{Testing and Evaluation}
To test the accuracy of our parser, we used a simple scheme in which we hand-wrote 77 test cases.
Each test case consists of a text file containing an English sentence, a start Karel world
(\texttt{.kwld}) file, and an expected end Karel world file. Each start and end Karel world file
contains a full text description of the state of the world at the start and end of each test
case---the size of the world; the positions and numbers of beepers at grid coordinates; the
position, orientation, and number of beepers held by the robot; and the position and orientation of
walls between grid coordinates. A complete description of the \texttt{.kwld} file format can be
found at \url{https://csis.pace.edu/~bergin/KarelJava2ed/karelexperimental.html}.

Assuming that the input sentence could be parsed and the generated Java source could be compiled,
we run the compiled Java program in the Karel simulator provided by~\newcite{Bergin:2013aa} and
obtain the final world state and compare it to the expected final world state. We scored our
parser's accuracy on an all-or-nothing scale: if the test and expected final world states match
exactly in beeper number and position and robot position, orientation, and number of beepers held,
the test case scores one point; otherwise, it scores zero points.

\section{Results}
Of our 77 test cases, the parser was successful in 21 of them, yielding a 27.27\% accuracy.
Table~\ref{tab:results-breakdown} presents a description of the categories of test cases we tested
our parser against and how many tests were passed in each category.

These results should probably be taken with a grain a salt because the majority of the
test cases that were passed were those that were written during the development of the parser,
whereas the majority of the test cases that were failed were written after the development of the
parser by a team member who did not participate in the development of the parser. This indicates
that the parser works on a very constrained subset of English, even more constrained than the
subset of English language that makes sense in the context of the Karel universe.

\begin{table*}[ht]
\centering
% \resizebox{\textwidth}{!}{%
    \begin{tabular}{lccc}
    \toprule
    Test category & \multicolumn{1}{p{2cm}}{\centering Number of passing tests} & \multicolumn{1}{p{3cm}}{\centering Total number of tests} & \multicolumn{1}{p{2cm}}{\centering Accuracy (\%)}\\ \midrule
    Simple imperative commands & 13 & 27 & 48 \\
    Conditional & 8 & 11 & 72 \\
    While & 0 & 23 & 0 \\
    For & 0 & 1 & 0 \\
    Combined conditional and while & 0 & 29 & 0 \\
    Combined conditional and for & 0 & 1 & 0 \\
    \bottomrule
    \end{tabular}
% }
\caption{Detailed breakdown of test case categories and successes in each category.}
\label{tab:results-breakdown}
\end{table*}


\section{Potential Improvements and Future Work}
If we were given more time, we would first aim to make the parser more full-featured. The current
parser implementation handles only an incomplete subset of possible Karel Java methods and checks
and also a limited subset of possible English sentences that can be used to describe Karel actions
and conditionals. For example, the parser currently does not generate code that corresponds to the
\texttt{nextToABeeper()} check, which returns true if there is a beeper on the same grid coordinate
as the robot. The parser also does not handle English sentences that express an intent to repeat
some action a finite number of times (i.e., something that would be expressed with a \texttt{for}
loop in Java).

We also considered testing alternative approaches to building the parser, including using a
synchronous grammar to translate between English and Java code and using machine learning to try to
learn how


% include your own bib file like this:
%\bibliographystyle{acl}
%\bibliography{acl2016}
\bibliography{report}
\bibliographystyle{acl2016}

\appendix

\section{Supplemental Material}
\label{sec:supplemental}
ACL 2016 also encourages the submission of supplementary material
to report preprocessing decisions, model parameters, and other details
necessary for the replication of the experiments reported in the
paper. Seemingly small preprocessing decisions can sometimes make
a large difference in performance, so it is crucial to record such
decisions to precisely characterize state-of-the-art methods.

Nonetheless, supplementary material should be supplementary (rather
than central) to the paper. It may include explanations or details
of proofs or deriations that do not fit into the paper, lists of
features or feature tempates, sample inputs and outputs for a system,
pseudo-code or source code, and data. (Source code and data should
be separate uploads, rather than part of the paper).

The paper should not rely on the supplementary material: while the paper
may refer to and cite the supplementary material will be available to the
reviewers, they will not be asked to review the
supplementary material.

Appendices (i.e. supplementary material in the form of proofs, tables,
or pseudo-code) should come after the references, as shown here. Use
\verb|\appendix| before any appendix section to switch the section
numbering over to letters.

\section{Multiple Appendices}
\dots can be gotten by using more than one section. We hope you won't
need that.

\end{document}
